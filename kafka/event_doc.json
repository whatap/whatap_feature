[
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714393200000,\"etime\":1714393800000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"8ba23d92-b4e0-4836-abe6-51cf31944655\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": " TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server\nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'oid', 'time', 'oid', 'Value', 'type', 'name' ]\nFILTER { key: \"Value\", exist: true }\nFILTER { key: \"type\", value: \"ReplicaManager\" }\nFILTER { key: \"name\", value: \"LeaderCount\" }\nFIRST-ONLY {key:'oid'}\nGROUP {timeunit:\"60s\", pk:\"pcode\", merge:[Value] }\nUPDATE { key:[Value], value:count }\nSELECT [\"Value\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "Value < 3",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Broker Count < 3",
    "event_message": "The current broker count is ${Value}. This is below the required threshold for normal operations and may affect cluster performance.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714391460000,\"etime\":1714392060000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"54b28e6a-eb81-4224-b0c4-a7362fdc9b03\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_controller\nTAGLOAD {backward:true}\nSELECT [ 'pcode','oid', 'time', 'oid', 'Value', 'type', 'name' ]\nFILTER { key: \"Value\", exist: true }\nFILTER { key: \"type\", value: \"KafkaController\" }\nFILTER { key: \"name\", value: \"ActiveControllerCount\" }\nFIRST-ONLY {key:oid}\nGROUP { timeunit:\"60s\", pk:\"pcode\", merge:[Value] }\nUPDATE { key:[Value], value:sum }\nSELECT [\"Value\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "Value != 1",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Controller Count Issue Detected",
    "event_message": "The number of active controllers is ${Value}. There should be exactly one active controller in the cluster.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714392060000,\"etime\":1714392660000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"2f0ff006-ced5-448d-88bf-a0debcb3ae89\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server \nTAGLOAD {backward: true}\nSELECT [ 'pcode', 'time', 'oid', 'OneMinuteRate', 'FifteenMinuteRate', 'pname', 'type', 'name' ]\nFILTER { key: \"OneMinuteRate\", exist: true }\nFILTER { key: \"FifteenMinuteRate\", exist: true }\nFILTER { key: \"pname\", exist: true }\nFILTER { key: \"type\", value: \"ReplicaManager\"}\nFILTER { key: \"name\", value: \"IsrShrinksPerSec\"}\nFIRST-ONLY {key:oid}\nGROUP { timegroup:\"60s\", merge: ['FifteenMinuteRate', 'OneMinuteRate']}\nUPDATE { key: ['OneMinuteRate','FifteenMinuteRate'], value: sum }\nSELECT [\"FifteenMinuteRate\",\"OneMinuteRate\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "FifteenMinuteRate*10 < OneMinuteRate",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "High ISR Expansion Rate",
    "event_message": "The ISR expansion rate has increased unexpectedly to ${OneMinuteRate} per minute. Monitor for potential stability issues.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714392660000,\"etime\":1714393260000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"6d797975-86a6-4ab8-ab93-ce8ba0d04ed6\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server \nTAGLOAD {backward: true}\nSELECT [ 'pcode', 'time', 'oid', 'OneMinuteRate','FifteenMinuteRate', 'pname', 'type', 'name' ]\nFILTER { key: \"OneMinuteRate\", exist: true }\nFILTER { key: \"pname\", exist: true }\nFILTER { key: \"type\", value: \"ReplicaManager\"}\nFILTER { key: \"name\", value: \"IsrShrinksPerSec\"}\nFIRST-ONLY {key:oid}\nGROUP { timeunit: 60s, merge: ['OneMinuteRate','FifteenMinuteRate']}\nUPDATE { key: [\"OneMinuteRate\",\"FifteenMinuteRate\"], value: sum }\nSELECT [\"FifteenMinuteRate\",\"OneMinuteRate\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "FifteenMinuteRate * 10 < OneMinuteRate",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Increased ISR Shrink Rate",
    "event_message": "The ISR shrink rate is currently ${OneMinuteRate} per minute. This could indicate synchronization problems among replicas.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1717398060000,\"etime\":1717398660000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2737],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"25c2fb0f-b6a6-4d5d-bcf8-c30a12d73707\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_network_request_channel \nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'time', 'oid', 'Value', 'oname', 'type', 'name' ]\nFILTER { key: \"Value\", exist: true }\nFILTER { key: \"oname\", exist: true }\nFILTER { key: \"type\", value: \"SocketServer\"}\nFILTER { key: \"name\", value: \"NetworkProcessorAvgIdlePercent\"}\nFIRST-ONLY {key:oid}\nCREATE { key:Usage, expr: \"(1 - Value) * 100\" }\nGROUP { timeunit: 60s, merge: ['Usage'] }\nUPDATE { key: ['Usage'], value: avg }\nselect [ Usage ]",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "Usage > 60",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Network Processor Usage Overload",
    "event_message": "Network Processor Usage($Usage)  > 60% Node: $oname",
    "stateful": true,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714379700000,\"etime\":1714380300000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"2febe921-21fc-4019-9d5e-d29d7b1443ba\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_controller\nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'time', 'oid', 'Value', 'type', 'name' ]\nFILTER { key: \"Value\", exist: true }\nFILTER { key: \"type\", value: \"KafkaController\" }\nFILTER { key: \"name\", value: \"OfflinePartitionsCount\" }\nFIRST-ONLY {key:oid}\nGROUP { timeunit:60s, pk:pcode, merge:[Value]}\nUPDATE { key:[Value], value:sum }\nSELECT [\"time\",\"Value\"]\n",
    "time_trim": 5000,
    "time_period": 30000,
    "rule": "Value > 0",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Offline Partitions Detected",
    "event_message": "There are currently ${Value} offline partitions. Immediate investigation and resolution are required to maintain cluster integrity.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1717403100000,\"etime\":1717403700000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2737],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"9d6cb656-404b-4138-b979-31f9a2bde7c9\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server\nTAGLOAD {backward: true}\n\nSELECT [ 'pcode', 'time', 'OneMinuteRate', 'pname', 'type', 'name' ]\nFILTER { key: \"OneMinuteRate\", exist: true }\nFILTER { key: \"pname\", exist: true }\nFILTER { key: \"type\", value: \"KafkaRequestHandlerPool\"}\nFILTER { key: \"name\", value: \"RequestHandlerAvgIdlePercent\"}\nFIRST-ONLY {key: oid}\nCREATE { key:\"Usage\", expr: \"(1 - OneMinuteRate)*100\" }\n\nGROUP { timeunit: 60s, merge: ['Usage']}\nUPDATE { key: ['Usage'], value: avg }\nselect [ \"Usage\" ]",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "Usage > 60",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Request Handler AVG Usage Overload",
    "event_message": "Request Handler AVG Usage > 60 broker:$oname",
    "stateful": true,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714391940000,\"etime\":1714392540000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"c35b6180-d34d-4912-b831-fad323b7f83e\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\n\nCATEGORY telegraf_kafka_controller\nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'time', 'oid', 'OneMinuteRate', 'type', 'name' ]\nFILTER { key: \"OneMinuteRate\", exist: true }\nFILTER { key: \"type\", value: \"ControllerStats\" }\nFILTER { key: \"name\", value: \"UncleanLeaderElectionsPerSec\" }\nFIRST-ONLY { key: \"oid\" }\nGROUP { timeunit:60s, pk:pcode, merge:[OneMinuteRate] }\nUPDATE { key:[OneMinuteRate], value:sum }\nSELECT [\"OneMinuteRate\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "OneMinuteRate > 0",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Unclean Leader Elections Occurring",
    "event_message": " There have been ${Value} unclean leader elections. This can lead to potential data loss.",
    "stateful": false,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714380660000,\"etime\":1714381260000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"4ae8ca05-6e0e-4c6e-bafc-2beb858f5448\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server\nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'time', 'oid', 'Value', 'type', 'name' ]\nFILTER { key: \"Value\", exist: true }\nFILTER { key: \"type\", value: \"ReplicaManager\" }\nFILTER { key: \"name\", value: \"UnderReplicatedPartitions\" }\nFIRST-ONLY { key: \"oid\" }\nGROUP { timeunit:60s, pk:pcode, merge:[Value] }\nUPDATE { key:[Value], value:sum }\nSELECT [\"time\",\"Value\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "Value > 0",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Under-Replicated Partitions Found",
    "event_message": "There are ${Value} under-replicated partitions in the cluster. This may risk data loss and reduced fault tolerance.",
    "stateful": true,
    "event_level": 30
  },
  {
    "desc": "{\"widgetType\":\"EXPERT\",\"supports\":[],\"isExpertEditable\":false,\"flexEventWidget\":{\"widgetType\":\"FLEX_EVENT\",\"id\":\"composite_metrics_widget\",\"requestApi\":\"LAST\",\"option\":{\"stime\":1714393020000,\"etime\":1714393620000,\"liveUpdateIntervalSec\":0,\"globalTime\":false,\"chart\":\"SERIES\",\"pcodes\":[2529],\"flex_event\":{\"category\":\"server_base\",\"tagPksGroup\":{\"pks\":[\"oid\"],\"timeunit\":5000},\"fieldsWithMerges\":[{\"key\":\"cpu\",\"timeMerge\":\"AVG\",\"objectMerge\":\"AVG\",\"unit\":\"PERCENT\",\"_label\":\"2165e90e-9e8b-49ee-969d-13b76585d625\"}]},\"chartAside\":{\"chart\":\"TABLE\"},\"timeAction\":\"CUSTOM\"},\"metrics\":[{\"mql\":\"INJECT timepast\\nHEADER { \\\"cpu$\\\":\\\"PERCENT\\\" }\\nOIDSET { oid:$oid, okind:$okind, onode:$onode }\\nCATEGORY \\\"server_base\\\"\\nTAGLOAD\\nINJECT default\\nUPDATE {key: cpu, value: avg}\\nGROUP {pk:[oid], timeunit: 5000}\\nUPDATE {key: cpu, value: avg}\\nCREATE {key: _id_, expr:\\\"oid\\\"}\\nCREATE {key: _name_, expr:\\\"oid\\\"} \\nSELECT [_name_, _id_, time, oid, cpu]\\n\"}]},\"pcode\":39397}",
    "enabled": false,
    "query": "TIME-RANGE {recent: 60s}\nCATEGORY telegraf_kafka_server \nTAGLOAD {backward:true}\nSELECT [ 'pcode', 'time', 'oid', 'OneMinuteRate', 'oname', 'type', 'name' ]\n\nFILTER { key: \"OneMinuteRate\", exist: true }\nFILTER { key: \"oname\", exist: true }\nFILTER { key: \"type\", value: \"SessionExpireListener\"}\nFILTER { key: \"name\", value: \"ZooKeeperExpiresPerSec\"}\nFIRST-ONLY {key:oid}\nGROUP { timeunit: 60s, merge: ['OneMinuteRate']}\nUPDATE { key: ['OneMinuteRate'], value: sum }\nSELECT [\"time\",\"OneMinuteRate\"]\n",
    "time_trim": 5000,
    "time_period": 60000,
    "rule": "FifteenMinuteRate*10 < OneMinuteRate",
    "interval_sec": 60,
    "silent_sec": 300,
    "event_title": "Zookeeper Connection Issues",
    "event_message": "Issues with Zookeeper synchronization have been detected. This may affect cluster stability and performance.",
    "stateful": false,
    "event_level": 30
  }
]